# API Keys
LLM_API_KEY=your_openai_api_key_here
EMBEDDING_API_KEY=your_openai_api_key_here

# Database Configuration
MONGODB_URI=mongodb://localhost:27017/character_chat
MONGODB_DB=character_chat
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Redis/Job Queue
REDIS_HOST=localhost
REDIS_PORT=6379

# LLM Configuration
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.2
LLM_BASE_URL=https://api.openai.com/v1

# Embedding Configuration
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_BASE_URL=https://api.openai.com/v1

# --- Worker & Processing Configuration ---
# Maximum number of parallel requests to send to the LLM provider
MAX_CONCURRENT_LLM_CALLS=10
# Maximum file size in MB for uploads
MAX_FILE_SIZE_MB=50
# Text chunking parameters
CHUNK_SIZE=1400
CHUNK_OVERLAP=200
# Number of chunks to retrieve for RAG context
RAG_RETRIEVAL_K=4
# Override embedding dimension (auto-detected by default)
VECTOR_SIZE=1536

# Storage
UPLOAD_ROOT=uploads

# Test utilities
API_BASE_URL=http://localhost:8000